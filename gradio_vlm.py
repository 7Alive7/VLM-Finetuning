import torch
import gradio as gr
from transformers import AutoTokenizer, AutoProcessor, AutoModelForCausalLM, AutoConfig
from config import VLMConfig
from train_with_attention_mask import VLM
from PIL import Image

# æ³¨å†Œè‡ªå®šä¹‰æ¨¡å‹
AutoConfig.register("vlm_model", VLMConfig)
AutoModelForCausalLM.register(VLMConfig, VLM)

# åˆå§‹åŒ–å…¨å±€å˜é‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
config = VLMConfig()

# è¿™é‡ŒæŠŠè·¯å¾„æ·»åŠ ä¸Šå³å¯
MODEL_PATHS = {
    "SFTæ¨¡å‹": "",
    "Pretrainæ¨¡å‹": ""
}


current_model = None
tokenizer = None
processor = None

# åŠ è½½æ¨¡å‹
def load_model(model_choice):
    global current_model, tokenizer, processor
    path = MODEL_PATHS[model_choice]
    current_model = AutoModelForCausalLM.from_pretrained(path).to(device)
    tokenizer = AutoTokenizer.from_pretrained(config.llm_path)
    processor = AutoProcessor.from_pretrained(config.vision_model_path)

    # æ›¿æ¢ lm_head
    qwen_model = AutoModelForCausalLM.from_pretrained(config.llm_path)
    current_model.llm.lm_head.load_state_dict(qwen_model.lm_head.state_dict())
    current_model.eval()

# èŠå¤©ä¸»é€»è¾‘
def chat(user_input, image, history_json, model_choice, temperature, top_p, pixel_values_state):
    if current_model is None:
        load_model(model_choice)

    if history_json is None or len(history_json) == 0:
        history = [{"role": "system", "content": "You are a helpful assistant."}]
        first_round = True
    else:
        history = history_json
        first_round = False

    # å›¾åƒå¤„ç†é€»è¾‘
    if first_round:
        if not user_input.endswith("\n<image>"):
            user_input = user_input + "\n<image>"
        image = image.convert("RGB")
        pixel_values = processor(images=image, return_tensors="pt")["pixel_values"].to(device)
        pixel_values_state = pixel_values  # ç¼“å­˜è§†è§‰ç‰¹å¾
    else:
        pixel_values = pixel_values_state  # å¤ç”¨ä¹‹å‰çš„è§†è§‰ç‰¹å¾

    history.append({"role": "user", "content": user_input})
    prompt_text = tokenizer.apply_chat_template(
        history,
        tokenize=False,
        add_generation_prompt=True
    ).replace("<image>", "<|image_pad|>" * config.image_pad_num)

    input_ids = tokenizer(prompt_text, return_tensors="pt").input_ids.to(device)
    attention_mask = torch.ones_like(input_ids)

    with torch.no_grad():
        output_ids = current_model.generate(
            input_ids=input_ids,
            attention_mask=attention_mask,
            pixel_values=pixel_values,
            max_new_tokens=256,
            temperature=temperature,
            top_p=top_p
        )

    answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)
    history.append({"role": "assistant", "content": answer})

    messages = [{"role": item["role"], "content": item["content"]} for item in history[1:]]
    return "", history, messages, pixel_values_state

# æ¸…é™¤å†å²å‡½æ•°
def clear_history():
    return [], [], "", None, None  # history, chatbot, input, image, pixel_values_state

# æ„å»º Gradio ç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ§  å¤šæ¨¡æ€å¯¹è¯ Demo (ä»…é¦–è½®ä¸Šä¼ å›¾åƒ)")

    with gr.Row():
        model_choice = gr.Radio(["SFTæ¨¡å‹", "Pretrainæ¨¡å‹"], label="é€‰æ‹©ä½¿ç”¨æ¨¡å‹", value="SFTæ¨¡å‹")

    with gr.Row():
        temperature = gr.Slider(0.0, 1.5, value=0.7, step=0.05, label="Temperature")
        top_p = gr.Slider(0.0, 1.0, value=0.9, step=0.05, label="Top-p")

    with gr.Row():
        with gr.Column(scale=1):
            image_input = gr.Image(type="pil", label="ä¸Šä¼ å›¾åƒ (ä»…ç¬¬ä¸€è½®ä½¿ç”¨)")

        with gr.Column(scale=2):
            chatbot = gr.Chatbot(label="å¤šè½®å¯¹è¯", type="messages")
            user_input = gr.Textbox(label="ä½ çš„é—®é¢˜", placeholder="è¾“å…¥æ–‡æœ¬å†…å®¹...")
            send_button = gr.Button("å‘é€")
            clear_button = gr.Button("æ¸…é™¤å†å²è®°å½•")

    history_state = gr.State([])
    pixel_values_state = gr.State(None)

    send_button.click(
        fn=chat,
        inputs=[user_input, image_input, history_state, model_choice, temperature, top_p, pixel_values_state],
        outputs=[user_input, history_state, chatbot, pixel_values_state]
    )

    clear_button.click(
        fn=clear_history,
        inputs=[],
        outputs=[history_state, chatbot, user_input, image_input, pixel_values_state]
    )

if __name__ == '__main__':
    demo.launch(share=False, server_name="0.0.0.0", server_port=7777)
